---
title: "AFM 423 - Group Project 2"
author: "Weixuan Xu 20568320"
date: "March 26, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
gc()
rm(list = ls())
```


```{r}
library(ggplot2)
library(ISLR)
library(dplyr)
library(tidyr)
library(pander)
library(forcats)
library(DMwR)
library(ROSE)
library(caret)


# 0. EDA (Aaron's Part)
#   0.0 Distribution of Results
#   0.1 Distribution of Variables



# 1. Remove Unwanted Columns
# Done?



# Prep 0: Read CSV
train = data.frame(read.csv("training.csv"))
train$VehicleAge = as.factor(train$VehicleAge)
train$IsBadBuy = as.factor(train$IsBadBuy)

train_clean = read.csv("training_cleaned.csv")
train_clean$VehicleAge = as.factor(train_clean$VehicleAge)
train_clean$IsBadBuy = as.factor(train_clean$IsBadBuy)


# PREP 1: Split
set.seed(42)
train_idx = createDataPartition(train$IsBadBuy, p = 0.70, list = FALSE)
train_clean_idx = createDataPartition(train_clean$IsBadBuy, p = 0.70, list = FALSE)

trn = train[train_idx, ]
tst = train[-train_idx, ]

trn_clean = train_clean[train_clean_idx, ]
tst_clean = train_clean[-train_clean_idx, ]


# Prep 2: SMOTE
trn_smote = SMOTE(IsBadBuy ~ ., data = trn, perc.over = 200)
tst_smote = SMOTE(IsBadBuy ~ ., data = tst, perc.over = 200)

trn_clean_smote = SMOTE(IsBadBuy ~ ., data = trn_clean, perc.over = 200)
tst_clean_smote = SMOTE(IsBadBuy ~ ., data = tst_clean, perc.over = 200)


# 2. Model Implementation
#   2.1 Logistic

default_glm_mod = train(
  form = IsBadBuy ~ .,
  data = trn_clean_smote,
  trControl = trainControl(method = "cv", number = 5),
  method = "glm",
  family = "binomial"
)
#   2.2 KNN
#   2.3 LDA
#   2.4 QDA
#   2.5 ...More from Daniel


# 3. Model Comparison with Scores/Curves/Measures


# 4. Conclusion

# 5. Feedback

```
